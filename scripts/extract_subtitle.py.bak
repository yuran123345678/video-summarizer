#!/usr/bin/env python3
"""
æ™ºèƒ½å­—å¹•æå–è„šæœ¬
æµç¨‹ï¼šå†…åµŒå­—å¹• â†’ çƒ§å½•å­—å¹•æ£€æµ‹(OCR) â†’ Whisperè¯­éŸ³è½¬å½•
"""

import subprocess
import sys
import os
import tempfile
from pathlib import Path
import json


def check_embedded_subtitle(video_path: str) -> tuple[bool, str]:
    """
    æ£€æŸ¥è§†é¢‘æ˜¯å¦åŒ…å«å†…åµŒå­—å¹•æµ
    è¿”å›: (æ˜¯å¦æœ‰å†…åµŒå­—å¹•, å­—å¹•æ–‡ä»¶è·¯å¾„æˆ–é”™è¯¯ä¿¡æ¯)
    """
    try:
        # ä½¿ç”¨ ffprobe æ£€æŸ¥å­—å¹•æµ
        cmd = [
            "ffprobe", "-v", "quiet", "-print_format", "json",
            "-show_streams", video_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        data = json.loads(result.stdout)
        
        streams = data.get("streams", [])
        subtitle_streams = [s for s in streams if s.get("codec_type") == "subtitle"]
        
        if subtitle_streams:
            # æå–ç¬¬ä¸€ä¸ªå­—å¹•æµ
            output_srt = video_path.rsplit(".", 1)[0] + "_embedded.srt"
            cmd = [
                "ffmpeg", "-y", "-i", video_path,
                "-map", f"0:s:0", output_srt
            ]
            subprocess.run(cmd, capture_output=True, check=True)
            return True, output_srt
        else:
            return False, "æ— å†…åµŒå­—å¹•æµ"
    except Exception as e:
        return False, f"æ£€æµ‹å¤±è´¥: {e}"


def capture_frame(video_path: str, timestamp: str = "00:00:05") -> str:
    """
    æˆªå–è§†é¢‘æŒ‡å®šæ—¶é—´çš„å¸§
    é»˜è®¤æˆªå–ç¬¬5ç§’ï¼ˆé€šå¸¸æœ‰å­—å¹•å‡ºç°ï¼‰
    """
    try:
        with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as tmp:
            frame_path = tmp.name
        
        cmd = [
            "ffmpeg", "-y", "-ss", timestamp, "-i", video_path,
            "-vframes", "1", "-q:v", "2", frame_path
        ]
        subprocess.run(cmd, capture_output=True, check=True)
        return frame_path
    except Exception as e:
        return ""


def check_burned_subtitle(frame_path: str) -> bool:
    """
    ä½¿ç”¨ OCR æ£€æµ‹ç”»é¢æ˜¯å¦æœ‰çƒ§å½•å­—å¹•
    è¿”å›: æ˜¯å¦æ£€æµ‹åˆ°å­—å¹•
    """
    try:
        from paddleocr import PaddleOCR
        
        ocr = PaddleOCR(
            use_angle_cls=True,
            lang='ch',
            show_log=False,
            use_gpu=False  # CPU è¿è¡Œ
        )
        
        result = ocr.ocr(frame_path, cls=True)
        
        # å¦‚æœæ£€æµ‹åˆ°æ–‡å­—ï¼Œè®¤ä¸ºæœ‰çƒ§å½•å­—å¹•
        if result and result[0]:
            text_count = len([line for line in result[0] if line])
            # æ£€æµ‹åˆ°è‡³å°‘3è¡Œæ–‡å­—ï¼Œè®¤ä¸ºæ˜¯å­—å¹•
            return text_count >= 3
        return False
    except ImportError:
        print("âš ï¸ PaddleOCR æœªå®‰è£…ï¼Œè·³è¿‡çƒ§å½•å­—å¹•æ£€æµ‹")
        return False
    except Exception as e:
        print(f"âš ï¸ OCR æ£€æµ‹å¤±è´¥: {e}")
        return False


def extract_burned_subtitle_ocr(video_path: str, output_srt: str) -> bool:
    """
    ä½¿ç”¨ OCR æå–çƒ§å½•å­—å¹•
    ç­–ç•¥ï¼šæ¯éš”1ç§’æˆªå–ä¸€å¸§ï¼ŒOCRè¯†åˆ«æ–‡å­—ï¼Œåˆå¹¶ä¸ºSRT
    """
    try:
        from paddleocr import PaddleOCR
        import cv2
        
        print("ğŸ” ä½¿ç”¨ OCR æå–çƒ§å½•å­—å¹•...")
        
        # è·å–è§†é¢‘æ—¶é•¿
        cmd = [
            "ffprobe", "-v", "error", "-show_entries",
            "format=duration", "-of", "default=noprint_wrappers=1:nokey=1",
            video_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True)
        duration = float(result.stdout.strip())
        
        ocr = PaddleOCR(
            use_angle_cls=True,
            lang='ch',
            show_log=False,
            use_gpu=False
        )
        
        # æ¯éš”1ç§’æˆªå–ä¸€å¸§è¿›è¡Œ OCR
        subtitles = []
        for t in range(0, int(duration), 1):
            frame_path = capture_frame(video_path, f"00:00:{t:02d}")
            if not frame_path:
                continue
            
            result = ocr.ocr(frame_path, cls=True)
            if result and result[0]:
                # æå–æ–‡å­—
                texts = []
                for line in result[0]:
                    if line:
                        text = line[1][0]
                        confidence = line[1][1]
                        if confidence > 0.7:  # ç½®ä¿¡åº¦é˜ˆå€¼
                            texts.append(text)
                
                if texts:
                    subtitles.append({
                        'index': len(subtitles) + 1,
                        'start': f"00:00:{t:02d},000",
                        'end': f"00:00:{t+1:02d},000",
                        'text': ' '.join(texts)
                    })
            
            os.unlink(frame_path)
        
        # å†™å…¥ SRT æ–‡ä»¶
        with open(output_srt, 'w', encoding='utf-8') as f:
            for sub in subtitles:
                f.write(f"{sub['index']}\n")
                f.write(f"{sub['start']} --> {sub['end']}\n")
                f.write(f"{sub['text']}\n\n")
        
        print(f"âœ… OCR æå–å®Œæˆ: {len(subtitles)} æ¡å­—å¹•")
        return True
        
    except Exception as e:
        print(f"âŒ OCR æå–å¤±è´¥: {e}")
        return False


def extract_with_whisper(video_path: str, output_srt: str, model: str = "large") -> bool:
    """
    ä½¿ç”¨ Whisper è¿›è¡Œè¯­éŸ³è½¬å½•
    """
    try:
        import whisper
        import torch
        
        print(f"ğŸ¤ ä½¿ç”¨ Whisper {model} è¿›è¡Œè¯­éŸ³è½¬å½•...")
        
        # æ£€æŸ¥ CUDA
        device = "cuda" if torch.cuda.is_available() else "cpu"
        if device == "cpu":
            print("âš ï¸ CUDA ä¸å¯ç”¨ï¼Œä½¿ç”¨ CPUï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
        
        # åŠ è½½æ¨¡å‹
        model = whisper.load_model(model, device=device)
        
        # è½¬å½•
        result = model.transcribe(
            video_path,
            language="zh",
            task="transcribe",
            verbose=False
        )
        
        # ç”Ÿæˆ SRT
        def format_timestamp(seconds: float) -> str:
            hours = int(seconds // 3600)
            minutes = int((seconds % 3600) // 60)
            secs = int(seconds % 60)
            millis = int((seconds % 1) * 1000)
            return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"
        
        with open(output_srt, 'w', encoding='utf-8') as f:
            for i, segment in enumerate(result["segments"], 1):
                start = format_timestamp(segment["start"])
                end = format_timestamp(segment["end"])
                text = segment["text"].strip()
                f.write(f"{i}\n{start} --> {end}\n{text}\n\n")
        
        print(f"âœ… Whisper è½¬å½•å®Œæˆ: {len(result['segments'])} æ¡å­—å¹•")
        return True
        
    except Exception as e:
        print(f"âŒ Whisper è½¬å½•å¤±è´¥: {e}")
        return False


def smart_subtitle_extraction(video_path: str, output_srt: str) -> tuple[bool, str]:
    """
    æ™ºèƒ½å­—å¹•æå–ä¸»å‡½æ•°
    æµç¨‹: å†…åµŒå­—å¹• â†’ çƒ§å½•å­—å¹•(OCR) â†’ Whisperè¯­éŸ³è½¬å½•
    
    è¿”å›: (æ˜¯å¦æˆåŠŸ, ä½¿ç”¨çš„æ¨¡å¼)
    """
    print("=" * 50)
    print("ğŸ¬ æ™ºèƒ½å­—å¹•æå–")
    print("=" * 50)
    print(f"è§†é¢‘: {video_path}")
    print()
    
    # æ­¥éª¤1: æ£€æŸ¥å†…åµŒå­—å¹•
    print("æ­¥éª¤ 1/3: æ£€æŸ¥å†…åµŒå­—å¹•...")
    has_embedded, result = check_embedded_subtitle(video_path)
    if has_embedded:
        print(f"âœ… å‘ç°å†…åµŒå­—å¹•ï¼Œå·²æå–: {result}")
        # å¤åˆ¶åˆ°ç›®æ ‡è·¯å¾„
        if result != output_srt:
            import shutil
            shutil.copy(result, output_srt)
        return True, "embedded"
    else:
        print(f"âš ï¸ {result}")
    
    # æ­¥éª¤2: æ£€æµ‹çƒ§å½•å­—å¹•
    print("\næ­¥éª¤ 2/3: æ£€æµ‹çƒ§å½•å­—å¹•...")
    frame_path = capture_frame(video_path, "00:00:05")
    if frame_path:
        has_burned = check_burned_subtitle(frame_path)
        os.unlink(frame_path)
        
        if has_burned:
            print("âœ… æ£€æµ‹åˆ°çƒ§å½•å­—å¹•ï¼Œä½¿ç”¨ OCR æå–...")
            if extract_burned_subtitle_ocr(video_path, output_srt):
                return True, "ocr"
        else:
            print("âš ï¸ æœªæ£€æµ‹åˆ°çƒ§å½•å­—å¹•")
    
    # æ­¥éª¤3: ä½¿ç”¨ Whisper
    print("\næ­¥éª¤ 3/3: ä½¿ç”¨ Whisper è¯­éŸ³è½¬å½•...")
    if extract_with_whisper(video_path, output_srt, "large"):
        return True, "whisper"
    
    return False, "failed"


def main():
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python extract_subtitle.py <è§†é¢‘è·¯å¾„> <è¾“å‡ºSRTè·¯å¾„>")
        sys.exit(1)
    
    video_path = sys.argv[1]
    output_srt = sys.argv[2]
    
    if not os.path.exists(video_path):
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        sys.exit(1)
    
    success, mode = smart_subtitle_extraction(video_path, output_srt)
    
    if success:
        print(f"\nâœ… å­—å¹•æå–æˆåŠŸï¼")
        print(f"   æ¨¡å¼: {mode}")
        print(f"   è¾“å‡º: {output_srt}")
        sys.exit(0)
    else:
        print(f"\nâŒ å­—å¹•æå–å¤±è´¥")
        sys.exit(1)


if __name__ == "__main__":
    main()
