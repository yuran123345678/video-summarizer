#!/usr/bin/env python3
"""
æ™ºèƒ½å­—å¹•æå–è„šæœ¬ - FunASR + RapidOCR ç‰ˆæœ¬
æµç¨‹ï¼šå†…åµŒå­—å¹• â†’ çƒ§å½•å­—å¹•æ£€æµ‹(RapidOCR) â†’ FunASRè¯­éŸ³è½¬å½•

æŠ€æœ¯æ ˆï¼š
- RapidOCR (ONNX): è½»é‡çº§ OCRï¼Œç”¨äºæå–çƒ§å½•å­—å¹•
- FunASR Nano: ä¸­æ–‡è¯­éŸ³è½¬å½•ï¼Œæ•ˆæœä¼˜äº Whisper
"""

import subprocess
import sys
import os
import tempfile
from pathlib import Path
import json


def check_embedded_subtitle(video_path: str) -> tuple[bool, str]:
    """
    æ£€æŸ¥è§†é¢‘æ˜¯å¦åŒ…å«å†…åµŒå­—å¹•æµ
    è¿”å›: (æ˜¯å¦æœ‰å†…åµŒå­—å¹•, å­—å¹•æ–‡ä»¶è·¯å¾„æˆ–é”™è¯¯ä¿¡æ¯)
    """
    try:
        cmd = [
            "ffprobe", "-v", "quiet", "-print_format", "json",
            "-show_streams", video_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        data = json.loads(result.stdout)
        
        streams = data.get("streams", [])
        subtitle_streams = [s for s in streams if s.get("codec_type") == "subtitle"]
        
        if subtitle_streams:
            output_srt = video_path.rsplit(".", 1)[0] + "_embedded.srt"
            cmd = [
                "ffmpeg", "-y", "-i", video_path,
                "-map", f"0:s:0", output_srt
            ]
            subprocess.run(cmd, capture_output=True, check=True)
            return True, output_srt
        else:
            return False, "æ— å†…åµŒå­—å¹•æµ"
    except Exception as e:
        return False, f"æ£€æµ‹å¤±è´¥: {e}"


def capture_frame(video_path: str, timestamp: str = "00:00:05") -> str:
    """æˆªå–è§†é¢‘æŒ‡å®šæ—¶é—´çš„å¸§"""
    try:
        with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as tmp:
            frame_path = tmp.name
        
        cmd = [
            "ffmpeg", "-y", "-ss", timestamp, "-i", video_path,
            "-vframes", "1", "-q:v", "2", frame_path
        ]
        subprocess.run(cmd, capture_output=True, check=True)
        return frame_path
    except Exception as e:
        return ""


def check_burned_subtitle(frame_path: str) -> bool:
    """ä½¿ç”¨ RapidOCR æ£€æµ‹ç”»é¢æ˜¯å¦æœ‰çƒ§å½•å­—å¹•"""
    try:
        from rapidocr_onnxruntime import RapidOCR
        
        ocr = RapidOCR()
        result = ocr(frame_path)
        
        # å¦‚æœæ£€æµ‹åˆ°æ–‡å­—ï¼Œè®¤ä¸ºæœ‰çƒ§å½•å­—å¹•
        if result and result[0]:
            text_count = len([line for line in result[0] if line])
            # æ£€æµ‹åˆ°è‡³å°‘2è¡Œæ–‡å­—ï¼Œè®¤ä¸ºæ˜¯å­—å¹•
            return text_count >= 2
        return False
    except ImportError:
        print("âš ï¸ RapidOCR æœªå®‰è£…ï¼Œè·³è¿‡çƒ§å½•å­—å¹•æ£€æµ‹")
        print("   å®‰è£…å‘½ä»¤: pip install rapidocr-onnxruntime")
        return False
    except Exception as e:
        print(f"âš ï¸ OCR æ£€æµ‹å¤±è´¥: {e}")
        return False


def extract_burned_subtitle_ocr(video_path: str, output_srt: str) -> bool:
    """ä½¿ç”¨ RapidOCR æå–çƒ§å½•å­—å¹•"""
    try:
        from rapidocr_onnxruntime import RapidOCR
        
        print("ğŸ” ä½¿ç”¨ RapidOCR æå–çƒ§å½•å­—å¹•...")
        
        cmd = [
            "ffprobe", "-v", "error", "-show_entries",
            "format=duration", "-of", "default=noprint_wrappers=1:nokey=1",
            video_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True)
        duration = float(result.stdout.strip())
        
        ocr = RapidOCR()
        
        # æ¯éš”2ç§’æˆªå–ä¸€å¸§è¿›è¡Œ OCRï¼ˆå‡å°‘è®¡ç®—é‡ï¼‰
        subtitles = []
        for t in range(0, int(duration), 2):
            frame_path = capture_frame(video_path, f"00:00:{t:02d}")
            if not frame_path:
                continue
            
            result = ocr(frame_path)
            if result and result[0]:
                # æå–æ–‡å­—
                texts = []
                for line in result[0]:
                    if line:
                        text = line[1]
                        confidence = line[2]
                        if confidence > 0.7:  # ç½®ä¿¡åº¦é˜ˆå€¼
                            texts.append(text)
                
                if texts:
                    subtitles.append({
                        'index': len(subtitles) + 1,
                        'start': f"00:00:{t:02d},000",
                        'end': f"00:00:{t+2:02d},000",
                        'text': ' '.join(texts)
                    })
            
            os.unlink(frame_path)
        
        # å†™å…¥ SRT æ–‡ä»¶
        with open(output_srt, 'w', encoding='utf-8') as f:
            for sub in subtitles:
                f.write(f"{sub['index']}\n")
                f.write(f"{sub['start']} --> {sub['end']}\n")
                f.write(f"{sub['text']}\n\n")
        
        print(f"âœ… OCR æå–å®Œæˆ: {len(subtitles)} æ¡å­—å¹•")
        return True
        
    except Exception as e:
        print(f"âŒ OCR æå–å¤±è´¥: {e}")
        return False


def extract_audio(video_path: str, audio_path: str) -> bool:
    """ä»è§†é¢‘ä¸­æå–éŸ³é¢‘"""
    try:
        cmd = [
            "ffmpeg", "-y", "-i", video_path,
            "-vn", "-acodec", "pcm_s16le",
            "-ar", "16000", "-ac", "1",
            audio_path
        ]
        subprocess.run(cmd, capture_output=True, check=True)
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ éŸ³é¢‘æå–å¤±è´¥: {e}")
        return False


def format_timestamp(seconds: float) -> str:
    """æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸º SRT æ ¼å¼"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"


def extract_with_funasr(video_path: str, output_srt: str) -> bool:
    """
    ä½¿ç”¨ FunASR è¿›è¡Œè¯­éŸ³è½¬å½•
    ä½¿ç”¨ Nano æ¨¡å‹ï¼Œè½»é‡ä¸”ä¸­æ–‡æ•ˆæœå¥½
    """
    try:
        from funasr import AutoModel
        
        print("ğŸ¤ ä½¿ç”¨ FunASR Nano è¿›è¡Œè¯­éŸ³è½¬å½•...")
        print("   æ¨¡å‹: iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch")
        
        # æå–éŸ³é¢‘
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
            audio_path = tmp.name
        
        if not extract_audio(video_path, audio_path):
            return False
        
        # åŠ è½½ FunASR æ¨¡å‹
        model = AutoModel(
            model="iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
            model_revision="v2.0.4",
            device="cpu",  # å¯æ ¹æ®å®é™…æƒ…å†µæ”¹ä¸º "cuda"
        )
        
        # è½¬å½•
        result = model.generate(
            input=audio_path,
            batch_size_s=300,
            hotword=''
        )
        
        # ç”Ÿæˆ SRT
        with open(output_srt, 'w', encoding='utf-8') as f:
            for i, res in enumerate(result, 1):
                if 'timestamp' in res and 'text' in res:
                    timestamps = res['timestamp']
                    text = res['text'].strip()
                    
                    if timestamps and len(timestamps) > 0:
                        start_sec = timestamps[0][0] / 1000  # æ¯«ç§’è½¬ç§’
                        end_sec = timestamps[-1][1] / 1000
                        
                        start = format_timestamp(start_sec)
                        end = format_timestamp(end_sec)
                        
                        f.write(f"{i}\n{start} --> {end}\n{text}\n\n")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(audio_path)
        
        print(f"âœ… FunASR è½¬å½•å®Œæˆ")
        return True
        
    except ImportError:
        print("âŒ FunASR æœªå®‰è£…")
        print("   å®‰è£…å‘½ä»¤: pip install funasr modelscope")
        return False
    except Exception as e:
        print(f"âŒ FunASR è½¬å½•å¤±è´¥: {e}")
        return False


def smart_subtitle_extraction(video_path: str, output_srt: str) -> tuple[bool, str]:
    """
    æ™ºèƒ½å­—å¹•æå–ä¸»å‡½æ•°
    æµç¨‹: å†…åµŒå­—å¹• â†’ çƒ§å½•å­—å¹•(RapidOCR) â†’ FunASRè¯­éŸ³è½¬å½•
    
    è¿”å›: (æ˜¯å¦æˆåŠŸ, ä½¿ç”¨çš„æ¨¡å¼)
    """
    print("=" * 50)
    print("ğŸ¬ æ™ºèƒ½å­—å¹•æå– (RapidOCR + FunASR)")
    print("=" * 50)
    print(f"è§†é¢‘: {video_path}")
    print()
    
    # æ­¥éª¤1: æ£€æŸ¥å†…åµŒå­—å¹•
    print("æ­¥éª¤ 1/3: æ£€æŸ¥å†…åµŒå­—å¹•...")
    has_embedded, result = check_embedded_subtitle(video_path)
    if has_embedded:
        print(f"âœ… å‘ç°å†…åµŒå­—å¹•ï¼Œå·²æå–: {result}")
        if result != output_srt:
            import shutil
            shutil.copy(result, output_srt)
        return True, "embedded"
    else:
        print(f"âš ï¸ {result}")
    
    # æ­¥éª¤2: æ£€æµ‹çƒ§å½•å­—å¹•
    print("\næ­¥éª¤ 2/3: æ£€æµ‹çƒ§å½•å­—å¹• (RapidOCR)...")
    frame_path = capture_frame(video_path, "00:00:05")
    if frame_path:
        has_burned = check_burned_subtitle(frame_path)
        os.unlink(frame_path)
        
        if has_burned:
            print("âœ… æ£€æµ‹åˆ°çƒ§å½•å­—å¹•ï¼Œä½¿ç”¨ RapidOCR æå–...")
            if extract_burned_subtitle_ocr(video_path, output_srt):
                return True, "ocr"
        else:
            print("âš ï¸ æœªæ£€æµ‹åˆ°çƒ§å½•å­—å¹•")
    
    # æ­¥éª¤3: ä½¿ç”¨ FunASR
    print("\næ­¥éª¤ 3/3: ä½¿ç”¨ FunASR Nano è¯­éŸ³è½¬å½•...")
    if extract_with_funasr(video_path, output_srt):
        return True, "funasr"
    
    return False, "failed"


def main():
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python extract_subtitle_funasr.py <è§†é¢‘è·¯å¾„> <è¾“å‡ºSRTè·¯å¾„>")
        sys.exit(1)
    
    video_path = sys.argv[1]
    output_srt = sys.argv[2]
    
    if not os.path.exists(video_path):
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        sys.exit(1)
    
    success, mode = smart_subtitle_extraction(video_path, output_srt)
    
    if success:
        print(f"\nâœ… å­—å¹•æå–æˆåŠŸï¼")
        print(f"   æ¨¡å¼: {mode}")
        print(f"   è¾“å‡º: {output_srt}")
        sys.exit(0)
    else:
        print(f"\nâŒ å­—å¹•æå–å¤±è´¥")
        sys.exit(1)


if __name__ == "__main__":
    main()
